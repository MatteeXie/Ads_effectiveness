{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 集成算法\n",
    "- 集成化算法是构建多个模型，通过某种策略把他们结合起来完成任务\n",
    "- 目的是为了获取更好的预测效果\n",
    "- 集成算法分为Bagging，Boosting，Stacking三大类\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、Bagging\n",
    "- 训练多个模型求平均\n",
    "- 训练时抽样，样本随机抽样，特征随机抽样，自助采样法（bootstrap sampling）\n",
    "![Bagging](https://img0.baidu.com/it/u=2098698089,3530436934&fm=253&fmt=auto&app=138&f=PNG?w=869&h=500)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、Boosting提升\n",
    "- AdaBoost算法、Xgboost算法、GBDT算法\n",
    "![Boosting](https://www.researchgate.net/publication/356698772/figure/fig2/AS:1096436418641951@1638422221975/The-architecture-of-Gradient-Boosting-Decision-Tree.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3、Stacking算法\n",
    "![stacking](https://miro.medium.com/v2/resize:fit:720/format:webp/1*GB8U0rAuCmsQi-26EOmgKw.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest随机森林\n",
    "- 随机森林是一种有决策树构成的Bagging算法\n",
    "- 森林：很多棵树\n",
    "- 随机：样本和特征都随机抽取（有放回随机抽取）\n",
    "- 分类时，让森林中每一棵决策树进行分类，森林的输出结果就是最多的那个类别\n",
    "- 回归时，去所有决策树的平均值\n",
    "- 随机森林可以计算自变量的重要性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import math\n",
    "import joblib\n",
    "from sklearn import metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**重要参数**\n",
    "- n_estimators：森林中树的数量\n",
    "- max_features :每棵决策树再选取特征是，特征的数量\n",
    "- max_depth：树的最大深度\n",
    "- min_samples_split：树节点最小分割的样本数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dldx/anaconda3/envs/torch/lib/python3.7/site-packages/sklearn/ensemble/_forest.py:564: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable OOB estimates.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9133333333333333"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFC = RandomForestClassifier(n_estimators=10, max_depth=3, oob_score=True)\n",
    "# oob是out od bag, 指每次抽样没有抽到的样例，oob_score指用oob数据测试的效果（正确率或R_sqr）\n",
    "# Bagging集成算法，可以不对数据进行train_test_split，而是使用oob_score\n",
    "\n",
    "RFC.fit(X,y)\n",
    "print(RFC.score(X,y))\n",
    "\n",
    "RFC.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.0952789 , 0.9047211 ],\n",
       "       [0.        , 0.0952789 , 0.9047211 ],\n",
       "       [0.        , 0.14552953, 0.85447047],\n",
       "       [0.        , 0.10436981, 0.89563019],\n",
       "       [0.        , 0.10436981, 0.89563019],\n",
       "       [0.        , 0.0952789 , 0.9047211 ],\n",
       "       [0.        , 0.12861224, 0.87138776],\n",
       "       [0.        , 0.0952789 , 0.9047211 ],\n",
       "       [0.        , 0.10436981, 0.89563019],\n",
       "       [0.        , 0.15956462, 0.84043538]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFC.predict_proba(X[-10:]) #预测样本中最后十个的概率值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.14061168, 0.01784783, 0.39413871, 0.44740178])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(iris.feature_names)\n",
    "RFC.feature_importances_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = datasets.load_boston()\n",
    "X = boston.data\n",
    "y = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFR = RandomForestRegressor(n_estimators=14, max_depth=4, oob_score=True)\n",
    "# oob是out od bag, 指每次抽样没有抽到的样例，oob_score指用oob数据测试的效果（正确率或R_sqr）\n",
    "# Bagging集成算法，可以不对数据进行train_test_split，而是使用oob_score\n",
    "\n",
    "RFR.fit(X,y)\n",
    "print(RFR.score(X,y))\n",
    "\n",
    "\n",
    "RFR.oob_prediction_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3.32954056e-02, 0.00000000e+00, 2.77678961e-03, 6.64188626e-05,\n",
       "       1.81191451e-02, 4.47094498e-01, 5.37892519e-03, 5.43998102e-02,\n",
       "       1.43576194e-03, 6.60369232e-03, 1.64497083e-02, 2.88151298e-03,\n",
       "       4.11498332e-01])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(boston.feature_names)\n",
    "RFR.feature_importances_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part1、 RFR applied in ads effectiveness prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/ads_3.csv\")\n",
    "\n",
    "X = df[df.columns[:62]]\n",
    "Y = df[df.columns[62:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = []\n",
    "RMSE = []\n",
    "R_squared = []\n",
    "R_squared_oob = []\n",
    "feature_importance = []\n",
    "\n",
    "for i in range(12):\n",
    "    y = Y[Y.columns[i]]\n",
    "    \n",
    "    RF_regression = RandomForestRegressor(n_estimators=15, max_depth=4, oob_score=True, n_jobs=-1)\n",
    "    RF_regression.fit(X, y)\n",
    "\n",
    "    joblib.dump(RF_regression, \"model/RF_regression/model{}.pkl\".format(i+1))\n",
    "    \n",
    "    MSE.append(metrics.mean_squared_error(y, RF_regression.predict(X)))\n",
    "    RMSE.append(math.sqrt(metrics.mean_squared_error(y, RF_regression.predict(X))))\n",
    "    R_squared.append(metrics.r2_score(y, RF_regression.predict(X)))\n",
    "    R_squared_oob.append(RF_regression.oob_score_)\n",
    "\n",
    "    feature_importance.append(list(RF_regression.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dic = {\"MSE\":MSE, \"RMSE\":RMSE, \"R_squared\":R_squared, \"R_squared_oob\":R_squared_oob}\n",
    "result_df = pd.DataFrame(result_dic, index=Y.columns)\n",
    "result_df.to_csv(\"result/RF_regression.csv\")\n",
    "\n",
    "feature_importance_df = pd.DataFrame(feature_importance, columns=X.columns, index=Y.columns)\n",
    "feature_importance_df.to_csv(\"result/RFR_feature_importance.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
