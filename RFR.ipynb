{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 集成算法\n",
    "- 集成化算法是构建多个模型，通过某种策略把他们结合起来完成任务\n",
    "- 目的是为了获取更好的预测效果\n",
    "- 集成算法分为Bagging，Boosting，Stacking三大类\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、Bagging\n",
    "- 训练多个模型求平均\n",
    "- 训练时抽样，样本随机抽样，特征随机抽样，自助采样法（bootstrap sampling）\n",
    "![Bagging](https://img0.baidu.com/it/u=2098698089,3530436934&fm=253&fmt=auto&app=138&f=PNG?w=869&h=500)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、Boosting提升\n",
    "- AdaBoost算法、Xgboost算法、GBDT算法\n",
    "![Boosting](https://www.researchgate.net/publication/356698772/figure/fig2/AS:1096436418641951@1638422221975/The-architecture-of-Gradient-Boosting-Decision-Tree.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3、Stacking算法\n",
    "![stacking](https://miro.medium.com/v2/resize:fit:720/format:webp/1*GB8U0rAuCmsQi-26EOmgKw.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest随机森林\n",
    "- 随机森林是一种有决策树构成的Bagging算法\n",
    "- 森林：很多棵树\n",
    "- 随机：样本和特征都随机抽取（有放回随机抽取）\n",
    "- 分类时，让森林中每一棵决策树进行分类，森林的输出结果就是最多的那个类别\n",
    "- 回归时，去所有决策树的平均值\n",
    "- 随机森林可以计算自变量的重要性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate#交叉验证\n",
    "from imblearn.over_sampling import RandomOverSampler #随机过采样\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import math\n",
    "import joblib\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**重要参数**\n",
    "- n_estimators：森林中树的数量\n",
    "- max_features :每棵决策树再选取特征是，特征的数量\n",
    "- max_depth：树的最大深度\n",
    "- min_samples_split：树节点最小分割的样本数"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part1、 RFR applied in ads effectiveness prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/ads_3.csv\")\n",
    "\n",
    "X = df[df.columns[:62]]\n",
    "Y = df[df.columns[62:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = []\n",
    "RMSE = []\n",
    "R_squared = []\n",
    "R_squared_oob = []\n",
    "feature_importance = []\n",
    "\n",
    "for i in range(12):\n",
    "    y = Y[Y.columns[i]]\n",
    "    \n",
    "    RF_regression = RandomForestRegressor(n_estimators=15, max_depth=4, oob_score=True, n_jobs=-1)\n",
    "    RF_regression.fit(X, y)\n",
    "\n",
    "    joblib.dump(RF_regression, \"model/RF_regression/model{}.pkl\".format(i+1))\n",
    "    \n",
    "    MSE.append(metrics.mean_squared_error(y, RF_regression.predict(X)))\n",
    "    RMSE.append(math.sqrt(metrics.mean_squared_error(y, RF_regression.predict(X))))\n",
    "    R_squared.append(metrics.r2_score(y, RF_regression.predict(X)))\n",
    "    R_squared_oob.append(RF_regression.oob_score_)\n",
    "\n",
    "    feature_importance.append(list(RF_regression.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dic = {\"MSE\":MSE, \"RMSE\":RMSE, \"R_squared\":R_squared, \"R_squared_oob\":R_squared_oob}\n",
    "result_df = pd.DataFrame(result_dic, index=Y.columns)\n",
    "result_df.to_csv(\"result/RF_regression.csv\")\n",
    "\n",
    "feature_importance_df = pd.DataFrame(feature_importance, columns=X.columns, index=Y.columns)\n",
    "feature_importance_df.to_csv(\"result/RFR_feature_importance.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part2、 RFC applied in ads effectiveness prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/ads_3.csv\")\n",
    "\n",
    "X = df[df.columns[:62]]\n",
    "Y = df[df.columns[62:]]\n",
    "Y = round(Y*10).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = []\n",
    "score_list = []\n",
    "\n",
    "for i in range(12):\n",
    "    y = Y[Y.columns[i]]\n",
    "    \n",
    "    RF_classification = RandomForestClassifier(n_estimators=15, max_depth=4, oob_score=True)\n",
    "    RF_classification.fit(X, y)\n",
    "\n",
    "    joblib.dump(RF_classification, \"model/RF_classification/model{}.pkl\".format(i+1))\n",
    "    score_list.append(RF_classification.oob_score_)\n",
    "    \n",
    "\n",
    "    feature_importance.append(list(RF_classification.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result_df = pd.DataFrame(score_list, index=Y.columns, columns=['ACC'])\n",
    "result_df.to_csv(\"./result/RF_classification.csv\")\n",
    "\n",
    "feature_importance_df = pd.DataFrame(feature_importance, columns=X.columns, index=Y.columns)\n",
    "feature_importance_df.to_csv(\"result/RFC_feature_importance.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part3、RFC_optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/ads_3.csv\")\n",
    "\n",
    "X = df[df.columns[:62]]\n",
    "Y = df[df.columns[62:]]\n",
    "Y = round(Y*10).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = []\n",
    "recall = []\n",
    "f1_score = []\n",
    "acc_validation = []\n",
    "acc_test = []\n",
    "\n",
    "for i in range(12):\n",
    "    y = Y[Y.columns[i]]\n",
    "    # 过采样\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    shuffle=True,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=0)\n",
    "    ros = RandomOverSampler()  \n",
    "    X_train, y_train = ros.fit_resample(X_train, y_train)   \n",
    "    \n",
    "    #网格搜索参数优化\n",
    "    params = {\n",
    "        \"n_estimators\":[10,50,100,150,200],\n",
    "        'max_depth':[3,5,8],\n",
    "        'max_features':[2,5,10],\n",
    "        'min_samples_leaf':[1,2,3],\n",
    "        'min_samples_split':[2,6],\n",
    "        'criterion':['gini', 'entropy']\n",
    "    }\n",
    "    \n",
    "    RF_classification = RandomForestClassifier()\n",
    "    model = GridSearchCV(RF_classification, param_grid=params, cv=5)\n",
    "    model.fit(X_train, y_train)\n",
    "    n_estimators = model.best_params_[\"n_estimators\"]\n",
    "    max_depth = model.best_params_[\"max_depth\"]\n",
    "    max_features = model.best_params_[\"max_features\"]\n",
    "    min_samples_leaf = model.best_params_[\"min_samples_leaf\"]\n",
    "    min_samples_split = model.best_params_[\"min_samples_split\"]\n",
    "    criterion = model.best_params_[\"criterion\"]\n",
    "\n",
    "    RF_classification = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, max_features=max_features, min_samples_leaf=min_samples_leaf, min_samples_split=min_samples_split, criterion=criterion)\n",
    "    cv_score = cross_validate(RF_classification       #实例化的模型\n",
    "\t\t\t\t, X   #完整的特征值\n",
    "\t\t\t\t, y #完整的目标值\n",
    "\t\t\t\t, cv=10         #几折交叉验证\n",
    "\t\t\t\t,scoring = [\"accuracy\",\"recall_macro\",\"f1_macro\"]   \n",
    "\t\t\t\t)\n",
    "    \n",
    "\n",
    "    recall.append(cv_score[\"test_recall_macro\"].mean())\n",
    "    f1_score.append(cv_score[\"test_f1_macro\"].mean())\n",
    "    acc_validation.append(cv_score[\"test_accuracy\"].mean())\n",
    "\n",
    "\n",
    "    RF_classification = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, max_features=max_features, min_samples_leaf=min_samples_leaf, min_samples_split=min_samples_split, criterion=criterion)\n",
    "    RF_classification.fit(X_train, y_train)\n",
    "\n",
    "    joblib.dump(RF_classification, \"model/RF_optimized_classification/model{}.pkl\".format(i+1))\n",
    "    acc_test.append(RF_classification.score(X_test,y_test))\n",
    "    \n",
    "    feature_importance.append(list(RF_classification.feature_importances_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dic = {\"recall\":recall, \"f1_score\":f1_score, \"acc_validation\":acc_validation, \"acc_test\":acc_test}\n",
    "result_df = pd.DataFrame(result_dic, index=Y.columns)\n",
    "result_df.to_csv(\"./result/RF_optimized_classification.csv\")\n",
    "\n",
    "feature_importance_df = pd.DataFrame(feature_importance, columns=X.columns, index=Y.columns)\n",
    "feature_importance_df.to_csv(\"result/RFC_optimized_feature_importance.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## part4、RFR_Optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/ads_3.csv\")\n",
    "\n",
    "X = df[df.columns[:62]]\n",
    "Y = df[df.columns[62:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = []\n",
    "RMSE = []\n",
    "R_squared_validation = []\n",
    "R_squared_test = []\n",
    "feature_importance = []\n",
    "\n",
    "for i in range(12):\n",
    "    y = Y[Y.columns[i]]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    shuffle=True,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=0)  \n",
    "    \n",
    "    #网格搜索参数优化\n",
    "    params = {\n",
    "        \"n_estimators\":[10,50,100,150,200],\n",
    "        'max_depth':[3,5,8],\n",
    "        'max_features':[2,5,10],\n",
    "        'min_samples_leaf':[1,2,3],\n",
    "        'min_samples_split':[2,6]\n",
    "        \n",
    "    }\n",
    "    \n",
    "    RF_regression = RandomForestRegressor()\n",
    "    model = GridSearchCV(RF_regression, param_grid=params, cv=5)\n",
    "    model.fit(X_train, y_train)\n",
    "    n_estimators = model.best_params_[\"n_estimators\"]\n",
    "    max_depth = model.best_params_[\"max_depth\"]\n",
    "    max_features = model.best_params_[\"max_features\"]\n",
    "    min_samples_leaf = model.best_params_[\"min_samples_leaf\"]\n",
    "    min_samples_split = model.best_params_[\"min_samples_split\"]\n",
    "\n",
    "    RF_regression = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, max_features=max_features, min_samples_leaf=min_samples_leaf, min_samples_split=min_samples_split)\n",
    "    cv_score = cross_validate(RF_regression       #实例化的模型\n",
    "\t\t\t\t, X   #完整的特征值\n",
    "\t\t\t\t, y #完整的目标值\n",
    "\t\t\t\t, cv=10         #几折交叉验证\n",
    "\t\t\t\t,scoring = [\"neg_mean_squared_error\",\"neg_root_mean_squared_error\",\"r2\"]   \n",
    "\t\t\t\t)\n",
    "\n",
    "    MSE.append(cv_score[\"test_neg_mean_squared_error\"].mean())\n",
    "    RMSE.append(cv_score[\"test_neg_root_mean_squared_error\"].mean())\n",
    "    R_squared_validation.append(cv_score[\"test_r2\"].mean())\n",
    "\n",
    "\n",
    "    RF_regression = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, max_features=max_features, min_samples_leaf=min_samples_leaf, min_samples_split=min_samples_split)\n",
    "    RF_regression.fit(X_train, y_train)\n",
    "\n",
    "    joblib.dump(RF_regression, \"model/RF_optimized_regression/model{}.pkl\".format(i+1))\n",
    "    R_squared_test.append(RF_regression.score(X_test,y_test))\n",
    "    \n",
    "    feature_importance.append(list(RF_regression.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dic = {\"MSE\":MSE, \"RMSE\":RMSE, \"R_squared_validation\":R_squared_validation, \"R_squared_test\":R_squared_test}\n",
    "result_df = pd.DataFrame(result_dic, index=Y.columns)\n",
    "result_df.to_csv(\"result/RF_optimized_regression.csv\")\n",
    "\n",
    "feature_importance_df = pd.DataFrame(feature_importance, columns=X.columns, index=Y.columns)\n",
    "feature_importance_df.to_csv(\"result/RFR_optimized_feature_importance.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 统计特征重要性\n",
    "import os\n",
    "from pyecharts import options as opts\n",
    "from pyecharts.charts import Bar\n",
    "from pyecharts.globals import ThemeType\n",
    "\n",
    "Feature = [round(i,3)for i in list(RandomForest.feature_importances_*100)]\n",
    "Columns = list(X.columns)\n",
    "c = (\n",
    "    Bar({\"theme\": ThemeType.MACARONS})\n",
    "    .add_xaxis(Columns)\n",
    "    .add_yaxis(\"Feature\", Feature)\n",
    "    .reversal_axis()\n",
    "    .set_series_opts(label_opts=opts.LabelOpts(position=\"right\",\n",
    "                                               formatter=\"{c} %\"))\n",
    "    .set_global_opts(title_opts=opts.TitleOpts(title=\"Feature Importances\"),\n",
    "                    xaxis_opts=opts.AxisOpts(axislabel_opts=opts.LabelOpts(formatter=\"{value} %\")))\n",
    ")\n",
    "\n",
    "\n",
    "PATH = './plots/'\n",
    "if not os.path.exists(PATH):  # 如果路径不存在\n",
    "    os.makedirs(PATH)\n",
    "    \n",
    "c.render(\"./plots/RandomForestClassifier_feature_importances.html\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
